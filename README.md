# Datathon21_T077

Team: Aparna Ayyah, Matt Ho, Bryan Ko

Please attach your youtube link down below:
{link:"https://www.youtube.com/watch?v=dQw4w9WgXcQ"}

Slides (Link to PDF): [link](https://www.example.com)
Slides (PDF): In repository, titled "slides.pdf"

**Key Components:**
- TIMIT corpus subset (Dataset: Race Column)
- Indic TTS (Dataset)
- CommonVoice (Dataset)
- Trained Model(RNN + TimeDistributed Layer)
- Demographics of Dataset Analysis (TIMIT_Demographic.py)
- DeepSpeech Model Code

**Instructions to Build:**
1. Step 1
2. Step 2
3. ...

**Sourced Cited:**
- Koenecke, Allison, et al. “Racial Disparities in Automated Speech Recognition.” 
- Scanlon, Dr. Patricia. “Voice Assistants Don't Work for Kids: The Problem with Speech Recognition in the Classroom.” 
- Masina, Fabio, et al. “Investigating the Accessibility of Voice Assistants With Impaired Users: Mixed Methods Study.” 
- Anusha Prakash, Anju Leela Thomas, S. Umesh and Hema A. Murthy, "Building Multilingual End-to-End Speech Synthesisers for Indian Languages".
- V, Anand P. “Indian Accent Speech Recognition.”
- Raju,Anirudh. “How to Make Neural Language Models Practical for Speech Recognition.”
- L. Lugosch, M. Ravanelli, P. Ignoto, V. Tomar, and Y. Bengio, "Speech Model Pre-training for End-to-End Spoken Language Understanding"




